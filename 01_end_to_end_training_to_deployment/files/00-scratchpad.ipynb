{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lovely-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "changed-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import class_weight\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import json as json\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.keras.utils import plot_model, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "still-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = 224\n",
    "input_width = 224\n",
    "input_chan = 3\n",
    "epochs = 1\n",
    "learnrate =0.1\n",
    "batchsize = 100\n",
    "output_ckpt_path = './build/chkpts/float_model.ckpt'\n",
    "infer_graph_path = './build/chkpts/inference_graph.pb'\n",
    "tboard_path = './build/tb_logs'\n",
    "num_classes = 43\n",
    "\n",
    "# Set up directories and files\n",
    "INFER_GRAPH_DIR = os.path.dirname(infer_graph_path)\n",
    "INFER_GRAPH_FILENAME =os.path.basename(infer_graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "experienced-addiction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "0. Agro-forestry areas\n",
      "1. Airports\n",
      "2. Annual crops associated with permanent crops\n",
      "3. Bare rock\n",
      "4. Beaches, dunes, sands\n",
      "5. Broad-leaved forest\n",
      "6. Burnt areas\n",
      "7. Coastal lagoons\n",
      "8. Complex cultivation patterns\n",
      "9. Coniferous forest\n",
      "10. Construction sites\n",
      "11. Continuous urban fabric\n",
      "12. Discontinuous urban fabric\n",
      "13. Dump sites\n",
      "14. Estuaries\n",
      "15. Fruit trees and berry plantations\n",
      "16. Green urban areas\n",
      "17. Industrial or commercial units\n",
      "18. Inland marshes\n",
      "19. Intertidal flats\n",
      "20. Land principally occupied by agriculture, with significant areas of natural vegetation\n",
      "21. Mineral extraction sites\n",
      "22. Mixed forest\n",
      "23. Moors and heathland\n",
      "24. Natural grassland\n",
      "25. Non-irrigated arable land\n",
      "26. Olive groves\n",
      "27. Pastures\n",
      "28. Peatbogs\n",
      "29. Permanently irrigated land\n",
      "30. Port areas\n",
      "31. Rice fields\n",
      "32. Road and rail networks and associated land\n",
      "33. Salines\n",
      "34. Salt marshes\n",
      "35. Sclerophyllous vegetation\n",
      "36. Sea and ocean\n",
      "37. Sparsely vegetated areas\n",
      "38. Sport and leisure facilities\n",
      "39. Transitional woodland/shrub\n",
      "40. Vineyards\n",
      "41. Water bodies\n",
      "42. Water courses\n",
      "Found 58008 validated image filenames belonging to 43 classes.\n",
      "Total Weight: 781663\n",
      "Found 62748 validated image filenames belonging to 43 classes.\n",
      "Found 41016 validated image filenames belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "#config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "#sess = tf.Session(config=config) \n",
    "#keras.backend.set_session(sess)\n",
    "\n",
    "# Silence TensorFlow messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# workaround for TF1.15 bug \"Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "class cfg:\n",
    "    weights = {\n",
    "        \"Agriculture\":                                               67256 ,\n",
    "        \"Airports\": 0,\n",
    "        \"Annual crops associated with permanent crops\" : 0,\n",
    "        \"Bare rock\": 0,\n",
    "        \"Beaches, dunes, sands\":0,\n",
    "        \"Burnt areas\":0,\n",
    "        \"Coastal lagoons\":0,\n",
    "        \"Construction sites\": 0,\n",
    "        \"Continuous urban fabric\": 0,\n",
    "        \"Discontinuous urban fabric\":0,\n",
    "        \"Estuaries\":0,\n",
    "        \"Fruit trees and berry plantations\":0,\n",
    "        \"Green urban areas\":0,\n",
    "        \"Land principally occupied by agriculture, with significant areas of natural vegetation\":0,\n",
    "        \"Mineral extraction sites\":0,\n",
    "        \"Inland marshes\":0,\n",
    "        \"Agro-forestry areas\":\t\t\t\t\t  15790 ,\n",
    "        \"Arable land\":\t\t\t\t\t\t 100394 ,\n",
    "        \"Beaches,dunes,sands\":\t\t\t\t\t   1193 ,\n",
    "        \"Broad-leaved forest\":\t\t\t\t\t  73407 ,\n",
    "        \"Coastal wetlands\":\t\t\t\t\t\t   1033 ,\n",
    "        \"Complex cultivation patterns\":\t\t\t\t  53530 ,\n",
    "        \"Coniferous forest\":\t\t\t\t\t  86569 ,\n",
    "        \"Dump sites\":0,\n",
    "        \"Industrial or commercial units\":\t\t\t\t   6182 ,\n",
    "        \"Inland waters\":\t\t\t\t\t\t  35349 ,\n",
    "        \"Inland wetlands\":\t\t\t\t\t\t  11620 ,\n",
    "        \"Intertidal flats\":0,\n",
    "        \"Marine waters\":\t\t\t\t\t\t  39110 ,\n",
    "        \"Mixed forest\":\t\t\t\t\t\t  91926 ,\n",
    "        \"Moors and heathland\":0,\n",
    "        \"Natural grassland\":0,\n",
    "        \"Moors,heathlandandsclerophyllousvegetation\":\t\t   8434 ,\n",
    "        \"Naturalgrasslandandsparselyvegetatedareas\":\t\t   6663 ,\n",
    "        \"Non-irrigated arable land\":0,\n",
    "        \"Olive groves\":0,\n",
    "        \"Peatbogs\":0,\n",
    "        \"Pastures\":\t\t\t\t\t\t  50977 ,\n",
    "        \"Permanent crops\":\t\t\t\t  15862 ,\n",
    "        \"Port areas\":0,\n",
    "        \"Rice fields\":0,\n",
    "        \"Road and rail networks and associated land\":0,\n",
    "        \"Permanently irrigated land\":0,\n",
    "        \"Salt marshes\":0,\n",
    "        \"Salines\":0,\n",
    "        \"Transitional woodland/shrub\":\t\t\t\t  77589 ,\n",
    "        \"Sclerophyllous vegetation\":0,\n",
    "        \"Sea and ocean\":0,\n",
    "        \"Urbanfabric\":\t\t\t\t\t  38779,\n",
    "        \"Sport and leisure facilities\":0,\n",
    "        \"Sparsely vegetated areas\":0,\n",
    "        \"Vineyards\":0,\n",
    "        \"Water bodies\":0,\n",
    "        \"Water courses\":0\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def get_data(path_images):\n",
    "    classes_arr = []\n",
    "    files = glob.glob(str(path_images) + \"/*/\" + '*.tif')\n",
    "\n",
    "    for filename in files:\n",
    "        out = Path(filename)\n",
    "        parent = out.resolve().parent\n",
    "        label_file = glob.glob(str(parent) + '/*.json')[0]\n",
    "\n",
    "        with open(label_file) as json_file:\n",
    "            data = json.load(json_file)\n",
    "        name = data['labels']\n",
    "        classes_arr.append([str(out), name])\n",
    "\n",
    "    return pd.DataFrame(classes_arr, columns=['files', 'labels'])\n",
    "\n",
    "# load data paths to dictionaries.\n",
    "#root_path = \"/root/tensorflow_datasets/\"\n",
    "root_path = \"/workspace/data/\"\n",
    "dict_train = get_data(root_path+\"train/\")\n",
    "dict_test = get_data(root_path+\"test/\")\n",
    "dict_val = get_data(root_path+\"val/\")\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(dict_train['labels'])\n",
    "print(\"Labels:\")\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "    print(\"{}. {}\".format(i, label))\n",
    "\n",
    "\n",
    "# Create Data Iterators\n",
    "#Data generator for training data\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dict_train,\n",
    "    x_col='files',\n",
    "    y_col='labels',\n",
    "    target_size=(input_height,input_width),\n",
    "    batch_size=batchsize,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "### Now compute class weights from this\n",
    "\n",
    "import sys\n",
    "weight_sum = sum([cfg.weights[x] for x in cfg.weights])\n",
    "print(\"Total Weight: %s\" % weight_sum)\n",
    "weights = {y:(cfg.weights[x] / weight_sum) for y,x in enumerate(mlb.classes_)}\n",
    "\n",
    "#Data generator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dict_test,\n",
    "    x_col='files',\n",
    "    y_col='labels',\n",
    "    target_size=(input_height,input_width),\n",
    "    batch_size=batchsize,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "#Data generator for validation data\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    dict_val,\n",
    "    x_col='files',\n",
    "    y_col='labels',\n",
    "    target_size=(input_height,input_width),\n",
    "    batch_size=batchsize,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "radical-classics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores: 32\n",
      "Num GPUs Available:  2\n",
      "\n",
      "----------------------------\n",
      " TRAINING STARTED...\n",
      "----------------------------\n",
      "581/580 [==============================] - ETA: 0s - loss: 0.1619 - precision: 0.6177 - recall: 0.1558\n",
      "Epoch 00001: val_loss improved from inf to 0.23214, saving model to ./build/chkpts/best-model.ckpt\n",
      "581/580 [==============================] - 498s 856ms/step - loss: 0.1619 - precision: 0.6177 - recall: 0.1558 - val_loss: 0.2321 - val_precision: 0.3322 - val_recall: 0.1188\n",
      "\n",
      "----------------------------\n",
      " TRAINING DONE...\n",
      "----------------------------\n",
      " Run `tensorboard --logdir=./build/tb_logs --port 6006 --host localhost` to see the results.\n"
     ]
    }
   ],
   "source": [
    "# get number of cores\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "print(\"Number of cores: %s\" %num_cpus)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "# Create a callback for storing the model. This will be used for quantization later\n",
    "fname = os.path.sep.join([INFER_GRAPH_DIR, \"best-model.ckpt\"])\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(fname,\n",
    "                            monitor=\"val_loss\", mode=\"min\",\n",
    "                            #monitor=\"val_acc\", mode=\"max\",\n",
    "                            save_best_only=True, verbose=1)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tboard_path)\n",
    "\n",
    "def create_model ():\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "    #hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/remote_sensing/bigearthnet-resnet50/1\", trainable=False, input_shape=(input_height,input_width, input_chan), )\n",
    "    #newInputs = tf.keras.layers.Input(shape=(input_height,input_width, input_chan))    # let us say this new InputLayer\n",
    "    #x = hub_layer (newInputs)\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    #newOutputs = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    #model = tf.keras.Model(newInputs, newOutputs)\n",
    "\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "    #hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/remote_sensing/bigearthnet-resnet50/1\", trainable=False, input_shape=(input_height,input_width, input_chan))\n",
    "    #model = tf.keras.Sequential()\n",
    "    #model.add(hub_layer)\n",
    "    #model.add(tf.keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "    #model = tf.keras.Sequential([\n",
    "    #    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4\",\n",
    "    #                   trainable=False),\n",
    "    #    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    #])\n",
    "    #model.build([None, 12, 12, 3])  # Batch input shape.\n",
    "\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "    #model = tf.keras.Sequential()\n",
    "    #model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",input_shape=(12,12,3)))\n",
    "    #model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(tf.keras.layers.Flatten())\n",
    "    #model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "    #model.add(tf.keras.layers.Dense(43, activation='softmax'))\n",
    "\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "    #resnet = tf.keras.applications.ResNet50(\n",
    "    #    include_top=False,\n",
    "    #    input_tensor=None,\n",
    "    #    input_shape=(input_height, input_width, input_chan),\n",
    "    #    pooling=None,\n",
    "    #    #classes=num_classes\n",
    "    #)\n",
    "    #newInputs = tf.keras.layers.Input(shape=(input_height,input_width, input_chan))\n",
    "    #\n",
    "    #x = resnet (newInputs)\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    #newOutputs = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    #\n",
    "    #model = tf.keras.Model(newInputs, newOutputs)\n",
    "    #\n",
    "    #return model\n",
    "\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    \n",
    "    resnet = tf.keras.applications.ResNet50V2 (\n",
    "        include_top=False,\n",
    "        input_tensor=None,\n",
    "        input_shape=(input_height, input_width, input_chan),\n",
    "        pooling=None,\n",
    "        #classes=num_classes\n",
    "    )\n",
    "    newInputs = tf.keras.layers.Input(shape=(input_height,input_width, input_chan))\n",
    "\n",
    "    x = resnet (newInputs)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    newOutputs = tf.keras.layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(newInputs, newOutputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "#with strategy.scope():\n",
    "model = create_model()\n",
    "model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=learnrate, momentum=0.9),\n",
    "        metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()] \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Training phase with training data\n",
    "print(\"\\n----------------------------\",flush=True)\n",
    "print(\" TRAINING STARTED...\",flush=True)\n",
    "print(\"----------------------------\",flush=True)\n",
    "\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "        steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[checkpoint, tensorboard_callback],\n",
    "        workers=num_cpus,\n",
    "        #class_weight=weights,\n",
    "        verbose=1\n",
    ")\n",
    "\n",
    "# Training phase with training data\n",
    "print(\"\\n----------------------------\",flush=True)\n",
    "print(\" TRAINING DONE...\",flush=True)\n",
    "print(\"----------------------------\",flush=True)\n",
    "\n",
    "\n",
    "print(' Run `tensorboard --logdir=%s --port 6006 --host localhost` to see the results.' % tboard_path,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "printable-harassment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Check the input and output name\\nprint (\"\\n TF input node name:\")\\nprint(model.inputs)\\nprint (\"\\n TF output node name:\")\\nprint(model.outputs)\\n\\nfname = os.path.sep.join([INFER_GRAPH_DIR, \"final-model.ckpt\"])\\ntf.keras.experimental.export_saved_model(model, fname)\\n\\nfreeze_graph.freeze_graph(None,\\n                      None,\\n                      None,\\n                      None,\\n                      model.outputs[0].op.name,\\n                      None,\\n                      None,\\n                      os.path.join(INFER_GRAPH_DIR, \"frozen_model.pb\"),\\n                      False,\\n                      \"\",\\n                      input_saved_model_dir=\\'build/chkpts/final-model.ckpt/\\')\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.keras.backend.set_learning_phase(0)\n",
    "\n",
    "# fetch the tensorflow session using the Keras backend\n",
    "#tf_session = tf.keras.backend.get_session()\n",
    "# write out tensorflow checkpoint & meta graph\n",
    "#saver = tf.compat.v1.train.Saver()\n",
    "#save_path = saver.save(tf_session, output_ckpt_path)\n",
    "#print (' Checkpoint created :', output_ckpt_path)\n",
    "\n",
    "# set up tensorflow saver object\n",
    "#saver = tf.compat.v1.train.Saver()\n",
    "#sess = tf.compat.v1.keras.backend.get_session()\n",
    "#saver.save(sess, output_ckpt_path)\n",
    "#model.save(filepath= output_ckpt_path)\n",
    "#tf.keras.models.save_model(model, filepath=INFER_GRAPH_DIR, save_format='tf')\n",
    "#with tf.compat.v1.Graph().as_default():\n",
    "    # define placeholders for the input data\n",
    "    #x_1 = tf.compat.v1.placeholder(tf.float32, shape=[None,input_height,input_width,input_chan], name='input_1')\n",
    "\n",
    "    # call the CNN function with is_training=False\n",
    "    #customcnn = tf.keras.Model(inputs=model.inputs,outputs=model.get_layer(name=\"dense\").output)\n",
    "    #logits_1 = customcnn(cnn_in=x_1, is_training=False)\n",
    "\n",
    "#    tf.io.write_graph(tf.compat.v1.get_default_graph().as_graph_def(), INFER_GRAPH_DIR, INFER_GRAPH_FILENAME, as_text=False)\n",
    "#    print(' Saved binary inference graph to %s' % infer_graph_path)\n",
    "\n",
    "#sess = tf.compat.v1.keras.backend.get_session()\n",
    "#tf.compat.v1.train.Saver().save(sess=sess, save_path=INFER_GRAPH_DIR)\n",
    "#tf.compat.v1.train.write_graph(graph_or_graph_def=sess.graph_def, logdir=INFER_GRAPH_DIR, name=infer_graph_path, as_text=False)\n",
    "# Method 1\n",
    "#freeze_graph.freeze_graph(input_graph=pbtxt_filepath, input_saver='', input_binary=False, input_checkpoint=ckpt_filepath, output_node_names='cnn/output', restore_op_name='save/restore_all', filename_tensor_name='save/Const:0', output_graph=pb_filepath, clear_devices=True, initializer_nodes='')\n",
    "\n",
    "'''\n",
    "from sklearn import metrics \n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "ground_truth = test_generator.classes\n",
    "\n",
    "y_true = MultiLabelBinarizer().fit_transform(ground_truth)\n",
    "y_pred = np.rint(predictions)\n",
    "y_score = predictions\n",
    "\n",
    "\n",
    "f = metrics.f1_score(y_true, y_pred, average='samples')\n",
    "p = metrics.precision_score(y_true, y_pred, average='samples')\n",
    "r = metrics.recall_score(y_true, y_pred, average='samples')\n",
    "AP = metrics.average_precision_score(y_true, y_score)\n",
    "lrap = metrics.label_ranking_average_precision_score(y_true, y_score)\n",
    "ji = metrics.jaccard_score(y_true, y_pred, average=\"samples\")\n",
    "#mAP = mAP(y_true, y_score)\n",
    "hl = metrics.hamming_loss(y_true, y_pred)\n",
    "rl = metrics.label_ranking_loss(y_true, y_score)\n",
    "cov = metrics.coverage_error(y_true, y_score)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "print(\"F1: \", f)\n",
    "print(\"presision: \",p)\n",
    "print(\"Recall: \", r)\n",
    "print(\"AP: \", AP) # edit to mAP\n",
    "print(\"lrap: \", lrap)\n",
    "print(\"Jaccard Index: \", ji)\n",
    "#print(\"mAP\", mAP)\n",
    "print(\"Hamming Loss: \", hl)\n",
    "print(\"Ranking Loss: \", rl)\n",
    "print(\"Coverage Error: \", cov)\n",
    "'''\n",
    "'''\n",
    "# Check the input and output name\n",
    "print (\"\\n TF input node name:\")\n",
    "print(model.inputs)\n",
    "print (\"\\n TF output node name:\")\n",
    "print(model.outputs)\n",
    "\n",
    "fname = os.path.sep.join([INFER_GRAPH_DIR, \"final-model.ckpt\"])\n",
    "tf.keras.experimental.export_saved_model(model, fname)\n",
    "\n",
    "freeze_graph.freeze_graph(None,\n",
    "                      None,\n",
    "                      None,\n",
    "                      None,\n",
    "                      model.outputs[0].op.name,\n",
    "                      None,\n",
    "                      None,\n",
    "                      os.path.join(INFER_GRAPH_DIR, \"frozen_model.pb\"),\n",
    "                      False,\n",
    "                      \"\",\n",
    "                      input_saved_model_dir='build/chkpts/final-model.ckpt/')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bright-browse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------\n",
      " SAVING CHECKPOINT & GRAPH...\n",
      "----------------------------\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Functional)      (None, 7, 7, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 43)                4315179   \n",
      "=================================================================\n",
      "Total params: 27,879,979\n",
      "Trainable params: 27,834,539\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "[<tf.Tensor 'input_2:0' shape=(None, 224, 224, 3) dtype=float32>]\n",
      "[<tf.Tensor 'dense/Sigmoid:0' shape=(None, 43) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# save post-training checkpoint, this saves all the parameters of the trained network\n",
    "print(\"\\n----------------------------\",flush=True)\n",
    "print(\" SAVING CHECKPOINT & GRAPH...\",flush=True)\n",
    "print(\"----------------------------\",flush=True)\n",
    "\n",
    "#model.build(input_shape=(None, 12,12,3))\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#print the CNN structure\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "model.summary()\n",
    "plot_model(model , show_shapes=True, show_layer_names=True, expand_nested=True)\n",
    "\n",
    "print (model.inputs)\n",
    "print (model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "directed-vienna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "dense\n",
      "input_2:0\n",
      "dense/Sigmoid:0\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].name)\n",
    "print(model.layers[-1].name)\n",
    "print(model.input.name)\n",
    "print(model.output.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "focused-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_learning_phase(0)\n",
    "fname = os.path.sep.join([INFER_GRAPH_DIR, \"final_model.ckpt\"]) \n",
    "#tf.compat.experimental.export_saved_model(model, fname) # tf 1\n",
    "tf.compat.v1.keras.experimental.export_saved_model(model, fname) # tf 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-number",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freeze_graph.freeze_graph(\n",
    "                      None,\n",
    "                      None,\n",
    "                      None,\n",
    "                      None,\n",
    "                      'dense/Sigmoid',\n",
    "                      None,\n",
    "                      None,\n",
    "                      os.path.join(INFER_GRAPH_DIR, \"frozen_model.pb\"),\n",
    "                      False,\n",
    "                      \"\",\n",
    "                      input_saved_model_dir='build/chkpts/final_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python generate_images.py --dataset=mnist --image_dir=./build/quantize/images --image_format=jpg --image_list=calib_list.txt --max_images=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!vai_q_tensorflow quantize --input_frozen_graph ./build/chkpts/frozen_model.pb --output_dir ./build/quantize/ --input_nodes 'conv2d_input' --output_nodes 'dense_1/Softmax' --input_shapes \"?,12,12,3\" --input_fn image_input_fn.calib_input\n",
    "#!vai_q_tensorflow quantize --input_frozen_graph ./build/chkpts/frozen_model.pb --output_dir ./build/quantize/ --input_nodes 'input_31' --output_nodes 'dense_10/Softmax' --input_shapes \"?,32,32,3\" --input_fn image_input_fn.calib_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    " #vai_q_tensorflow quantize --input_frozen_graph ./build/chkpts/frozen_model.pb --output_dir ./build/quantize/ --input_nodes 'input_2' --output_nodes 'dense/Sigmoid' --input_shapes \"?,224,224,3\" --input_fn image_input_fn.calib_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(model.layers[1].get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.ResNet50V2 (\n",
    "    include_top=False,\n",
    "    input_tensor=None,\n",
    "    input_shape=(input_height, input_width, input_chan),\n",
    "    pooling=None,\n",
    "    #classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(hub_layer.get_weights()))\n",
    "print (len(resnet.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = hub_layer.variables[0]\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in hub_layer.variables:\n",
    "    print (item.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_layer.input\n",
    "hub_layer.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_layer.output.op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_layer.output.op.node_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_layer.output.op.op_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/bin/vai_q_tensorflow quantize --input_frozen_graph ./build/chkpts/frozen_model.pb --output_dir ./build/quantize/ --input_nodes 'input_1' --output_nodes 'dense/Sigmoid' --input_shapes \"?,32,32,3\" --input_fn image_input_fn.calib_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ops.Graph()\n",
    "with graph.as_default():\n",
    "    importer.import_graph_def(input_graph_def, name='')\n",
    "    input_graph_def = graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-gasoline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-allergy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
